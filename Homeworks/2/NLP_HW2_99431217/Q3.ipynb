{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8Wio74Smvmm"
      },
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oCb3cVwzrfbb"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# SOURCE_DIR = '/content/Q3_data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HtCgCrUVtU_J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uEa_gZkKmvmv"
      },
      "outputs": [],
      "source": [
        "def delete_hashtag_usernames(text):\n",
        "  try:\n",
        "    result = []\n",
        "    for word in text.split():\n",
        "      if word[0] not in ['@', '#']:\n",
        "        result.append(word)\n",
        "    return ' '.join(result)\n",
        "  except:\n",
        "    return ''\n",
        "\n",
        "def delete_url(text):\n",
        "  text = re.sub(r'http\\S+', '', text)\n",
        "  return text\n",
        "\n",
        "def delete_ex(text):\n",
        "  text = re.sub(r'\\u200c', '', text)\n",
        "  return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz4cWWgA4xBF"
      },
      "source": [
        "# 0. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0FjQ9_ZMkve",
        "outputId": "c1b4a058-3ded-4302-bc64-bf995b656b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting json-lines\n",
            "  Downloading json_lines-0.5.0-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from json-lines) (1.16.0)\n",
            "Installing collected packages: json-lines\n",
            "Successfully installed json-lines-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install json-lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uf7K92-olSfe"
      },
      "outputs": [],
      "source": [
        "import json_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bG5awXKo40HS"
      },
      "outputs": [],
      "source": [
        "# 1. extract all tweets from file and save them in memory\n",
        "# 2. remove urls, hashtags and usernames. use the prepared functions\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('Q3_data.csv')\n",
        "# print(data.columns)\n",
        "\n",
        "PureText_data = data['PureText']\n",
        "\n",
        "# Apply preprocessing functions to the tweet data\n",
        "PureText_data = PureText_data.apply(delete_hashtag_usernames)\n",
        "PureText_data = PureText_data.apply(delete_url)\n",
        "PureText_data = PureText_data.apply(delete_ex)\n",
        "\n",
        "# Print the preprocessed tweet data\n",
        "# print(data['Text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cncc0Uxvmvmy"
      },
      "source": [
        "# 1. Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZjVk9qgmvmz"
      },
      "source": [
        "## Cosine Similarity\n",
        "\n",
        "To measure the similarity between two words, you need a way to measure the degree of similarity between two embedding vectors for the two words. Given two vectors $u$ and $v$, cosine similarity is defined as follows:\n",
        "\n",
        "$$\\text{CosineSimilarity(u, v)} = \\frac {u \\cdot v} {||u||_2 ||v||_2} = cos(\\theta)Â \\tag{1}$$\n",
        "\n",
        "* $u \\cdot v$ is the dot product (or inner product) of two vectors\n",
        "* $||u||_2$ is the norm (or length) of the vector $u$\n",
        "* $\\theta$ is the angle between $u$ and $v$.\n",
        "* The cosine similarity depends on the angle between $u$ and $v$.\n",
        "    * If $u$ and $v$ are very similar, their cosine similarity will be close to 1.\n",
        "    * If they are dissimilar, the cosine similarity will take a smaller value.\n",
        "\n",
        "<img src=\"images/cosine_sim.png\" style=\"width:800px;height:250px;\">\n",
        "<caption><center><font color='purple'><b>Figure 1</b>: The cosine of the angle between two vectors is a measure of their similarity.</font></center></caption>\n",
        "\n",
        "Implement the function `cosine_similarity()` to evaluate the similarity between word vectors.\n",
        "\n",
        "**Reminder**: The norm of $u$ is defined as $ ||u||_2 = \\sqrt{\\sum_{i=1}^{n} u_i^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dfiK-Lw7mvm0"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Cosine similarity reflects the degree of similarity between u and v\n",
        "\n",
        "    Arguments:\n",
        "        u -- a word vector of shape (n,)\n",
        "        v -- a word vector of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
        "    \"\"\"\n",
        "\n",
        "    dot_product = np.dot(u, v)\n",
        "    norm_u = np.sqrt(np.sum(u**2))\n",
        "    norm_v = np.sqrt(np.sum(v**2))\n",
        "    cosine_similarity = dot_product / (norm_u * norm_v)\n",
        "\n",
        "    return cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLDGkeBRmvm0"
      },
      "source": [
        "## find k nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EaO0XQvKmvm1"
      },
      "outputs": [],
      "source": [
        "def find_k_nearest_neighbors(word, embedding_dict, k):\n",
        "  \"\"\"\n",
        "    implement a function to return the nearest words to an specific word based on the given dictionary\n",
        "\n",
        "    Arguments:\n",
        "        word           -- a word, string\n",
        "        embedding_dict -- dictionary that maps words to their corresponding vectors\n",
        "        k              -- the number of word that should be returned\n",
        "\n",
        "    Returns:\n",
        "        a list of size k consisting of the k most similar words to the given word\n",
        "\n",
        "    Note: use the cosine_similarity function that you have implemented to calculate the similarity between words\n",
        "    \"\"\"\n",
        "  # Ensure the word is in the embedding dictionary\n",
        "  if word not in embedding_dict:\n",
        "      return []\n",
        "\n",
        "  # Get the embedding for the word\n",
        "  word_embedding = embedding_dict[word]\n",
        "\n",
        "  # Calculate cosine similarity with all other words\n",
        "  similarities = {}\n",
        "  for other_word, other_embedding in embedding_dict.items():\n",
        "      # print(\"Other word is: \", other_word)\n",
        "      # print(\"other_embedding is: \", other_embedding)\n",
        "      if other_word != word:\n",
        "          sim = cosine_similarity(word_embedding, other_embedding)\n",
        "          similarities[other_word] = sim\n",
        "          # if sim != 0.0:\n",
        "            # print(\"sim is: \", sim)\n",
        "  # print (\"Similarities is: \", similarities)\n",
        "  # Sort by similarity\n",
        "  sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "  # Extract the top k words\n",
        "  # neighbors = [word for word, _ in sorted_similarities[:k]]\n",
        "  neighbors = sorted_similarities[:k]\n",
        "\n",
        "  return neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqr5DLDYuKd-"
      },
      "source": [
        "# 2. One hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. find one hot encoding of each word\n",
        "\n",
        "words = PureText_data.str.split().tolist()\n",
        "words = [word for sublist in words for word in sublist]\n",
        "# print(words[1003])\n",
        "\n",
        "# Reshape the words to be a column vector\n",
        "words_array = np.array(words).reshape(-1, 1)\n",
        "# print(words_array)\n",
        "\n",
        "# Create the encoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Fit and transform the words to one-hot encoded vectors\n",
        "one_hot_encoded = encoder.fit_transform(words_array)\n",
        "\n",
        "# # Create a DataFrame to view the one-hot encoded words\n",
        "# one_hot_df = pd.DataFrame(one_hot_encoded, index=words, columns=encoder.get_feature_names_out())\n",
        "\n",
        "# # Display the one-hot encoded DataFrame\n",
        "# print(one_hot_df)"
      ],
      "metadata": {
        "id": "qIZzhK_El9Al",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6eb060-28b3-4fba-f327-602956b933ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPqc0I0yuNlI",
        "outputId": "0ce21674-0192-419c-8fbc-343ce04b709b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Ø¨Ù†Ø´ÛŒÙ†', 0.0), ('ØªØ§', 0.0), ('Ø´ÙˆØ¯', 0.0), ('Ù†Ù‚Ø´', 0.0), ('ÙØ§Ù„', 0.0), ('Ù…Ø§', 0.0), ('Ù‡Ù…', 0.0), ('ÙØ±Ø¯Ø§', 0.0), ('Ø´Ø¯Ù†', 0.0), ('Ø§ÛŒÙ†', 0.0)]\n",
            "[('Ø¨Ù†Ø´ÛŒÙ†', 0.0), ('ØªØ§', 0.0), ('Ø´ÙˆØ¯', 0.0), ('Ù†Ù‚Ø´', 0.0), ('ÙØ§Ù„', 0.0), ('Ù…Ø§', 0.0), ('Ù‡Ù…', 0.0), ('ÙØ±Ø¯Ø§', 0.0), ('Ø´Ø¯Ù†', 0.0), ('Ø§ÛŒÙ†', 0.0)]\n"
          ]
        }
      ],
      "source": [
        "# 2. find 10 nearest words from \"Ø¢Ø²Ø§Ø¯ÛŒ\"\n",
        "embedding_dict = {word: encoding for word, encoding in zip(words, one_hot_encoded)}\n",
        "\n",
        "word = \"Ø¢Ø²Ø§Ø¯ÛŒ\"\n",
        "k = 10\n",
        "nearest_words = find_k_nearest_neighbors(word, embedding_dict, k)\n",
        "print(nearest_words)\n",
        "\n",
        "word = \"Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±\"\n",
        "nearest_words = find_k_nearest_neighbors(word, embedding_dict, k)\n",
        "print(nearest_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each and every vector in the one hot encoding is orthogonal to each other. So the cosine similarity as well as distance between any two vectors are same. Thus it holds no relationship among them.\n",
        "That is why the nearest words found are the same. The cosine similarity of each pair of words equals 0."
      ],
      "metadata": {
        "id": "_yinx6QW8EfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Just testing\n",
        "count = 0\n",
        "for value in embedding_dict['Ø¢Ø²Ø§Ø¯ÛŒ']:\n",
        "  if value != 0.0:\n",
        "    print(count, value)\n",
        "  count = count + 1\n",
        "\n",
        "count = 0\n",
        "for value in embedding_dict['Ø¨Ù‡Ø§Ø±Ù‡']:\n",
        "  if value != 0.0:\n",
        "    print(count, value)\n",
        "  count = count + 1\n",
        "\n",
        "count = 0\n",
        "for value in embedding_dict['Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±']:\n",
        "  if value != 0.0:\n",
        "    print(count, value)\n",
        "  count = count + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pasR5WChpOKV",
        "outputId": "f5257422-1900-4f7b-8f31-601c7bbc0c50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1805 1.0\n",
            "7146 1.0\n",
            "28946 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FayPXc1mvm2"
      },
      "source": [
        "##### Describe advantages and disadvantages of one-hot encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9tAFn4brKrB"
      },
      "source": [
        "**Advantages:**\n",
        "\n",
        "1. **Simplicity:** One-hot encoding is a straightforward and simple method to represent categorical variables. It involves creating a binary vector where each element corresponds to a unique category, making it easy to understand and implement.\n",
        "\n",
        "2. **Retains categorical information:** One-hot encoding preserves the categorical nature of the variable. Each category is represented by a separate binary variable, allowing models to capture relationships and patterns specific to each category.\n",
        "\n",
        "3. **Compatibility with machine learning algorithms:** Many machine learning algorithms require numerical inputs. One-hot encoding converts categorical variables into a numeric format that can be readily used by these algorithms.\n",
        "\n",
        "4. **Avoids ordinality assumption:** One-hot encoding treats all categories as independent and does not impose any ordinal relationship between categories. This is useful when there is no inherent order or hierarchy among the categories.\n",
        "\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "1. **Dimensionality:** One-hot encoding expands the dimensionality of the feature space. If a categorical variable has a large number of unique categories, the resulting one-hot encoded representation can lead to a high-dimensional feature space, which may impact computational efficiency and model complexity.\n",
        "\n",
        "2. **Curse of dimensionality:** The increase in dimensionality due to one-hot encoding can lead to the curse of dimensionality. This refers to the problem where the number of features becomes large relative to the number of observations, which can result in sparse data, increased model complexity, and overfitting.\n",
        "\n",
        "3. **Redundancy:** One-hot encoding can introduce redundancy in the data representation. Since each category is represented by a separate binary variable, there is a perfect correlation between these variables. This redundancy can lead to multicollinearity issues in some models.\n",
        "\n",
        "4. **Handling new categories:** One-hot encoding requires defining the set of categories in advance. If new categories appear during testing or deployment, the one-hot encoding scheme may not handle them properly. This can be particularly problematic in real-world scenarios where new categories may emerge over time.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHeSYFUKw5gw"
      },
      "source": [
        "# 3. TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets = data['Text']\n",
        "print(Tweets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WUmrM9dsOMS",
        "outputId": "91ed4a55-8fc7-4f37-f6ee-7987b0f883b3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        Ø¨Ù†Ø´ÛŒÙ† ØªØ§ Ø´ÙˆØ¯ Ù†Ù‚Ø´ ÙØ§Ù„ Ù…Ø§ \\nÙ†Ù‚Ø´ Ù‡Ù…â€Œ ÙØ±Ø¯Ø§ Ø´Ø¯Ù†\\n#Ù…...\n",
            "1        @Tanasoli_Return @dr_moosavi Ø§ÛŒÙ† Ú¯ÙˆØ²Ùˆ Ø±Ùˆ Ú©ÛŒ Ú¯Ø±...\n",
            "2        @ghazaleghaffary Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ±Ø§Ù†ØŒ Ø¨Ø±Ø§ÛŒ Ù…Ù‡Ø³Ø§.\\n#OpIr...\n",
            "3        @_hidden_ocean Ù…Ø±Ú¯ Ø¨Ø± Ø¯ÛŒÚ©ØªØ§ØªÙˆØ± \\n#OpIran \\n#Ma...\n",
            "4        Ù†Ø°Ø§Ø±ÛŒÙ… Ø®ÙˆÙ†Ø´ÙˆÙ† Ù¾Ø§ÛŒÙ…Ø§Ù„ Ø´Ù‡.â€Œâ€Œ.â€Œâ€Œ.\\n#Mahsa_Amini #...\n",
            "                               ...                        \n",
            "19995    Ø¨Ø±Ø§ÛŒ Ø§ÛŒØ±Ø§Ù† Ø¨Ø§Ù†Ùˆ #Mahsa_Amini      #MahsaAmini ...\n",
            "19996    @MohammadTehra16 @mimpedram Ø§Ø² Ø¨Ø³ Ø­Ø§Ø¬ Ø®Ø§Ù†Ù… Ø¯Ø±Ø§...\n",
            "19997    Ø¨Ù‡ Ø§ÙØªØ®Ø§Ø± Ø§Ø² Ø¨ÛŒÙ† Ø±ÙØªÙ† Ø¬Ù…Ù‡ÙˆØ±ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒğŸ™†â€â™‚ï¸ğŸ™†â€â™‚ï¸ğŸ™†â€â™‚...\n",
            "19998    Ù¾Ù†Ø¬Ø§Ù‡ Ùˆ Ø´ÛŒØ´ \\n\\n#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \\n#Mahsa_Amini \\n#...\n",
            "19999    Ø¯Ø± Ù…Ø­ÛŒØ· Ø·ÙˆÙØ§Ù†â€ŒØ²Ø§ÛŒ Ù…Ø§Ù‡Ø±Ø§Ù†Ù‡ Ø¯Ø± Ø¬Ù†Ú¯ Ø§Ø³Øª\\nÙ†Ø§Ø®Ø¯Ø§ÛŒ Ø§...\n",
            "Name: Text, Length: 20000, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. find the TF-IDF of all tweets.\n",
        "########## import and preprocess (PureText_data)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# # Create a document-term matrix\n",
        "# vectorizer = TfidfVectorizer()\n",
        "# document_term_matrix = vectorizer.fit_transform(Tweets)\n",
        "\n",
        "# # Calculate the TF-IDF values\n",
        "# tfidf_values = document_term_matrix.toarray()\n",
        "\n",
        "# # Normalize the TF-IDF values\n",
        "# normalized_tfidf = tfidf_values / np.linalg.norm(tfidf_values, axis=1, keepdims=True)\n",
        "\n",
        "# # Print the TF-IDF values for the first 10 tweets\n",
        "# for i in range(10):\n",
        "#     print(\"Tweet:\", Tweets[i])\n",
        "#     print(\"TF-IDF:\", normalized_tfidf[i])\n",
        "#     print()\n",
        "\n",
        "# Create a TfidfVectorizer object and fit it to the preprocessed corpus\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(words)\n",
        "\n",
        "# Transform the preprocessed corpus into a TF-IDF matrix\n",
        "tf_idf_matrix = vectorizer.transform(words)\n",
        "\n",
        "# Get list of feature names that correspond to the columns in the TF-IDF matrix\n",
        "print(\"Feature Names:\\n\", vectorizer.get_feature_names_out())\n",
        "\n",
        "# Print the resulting matrix\n",
        "print(\"TF-IDF Matrix:\\n\", tf_idf_matrix.toarray())\n",
        "# for i in tf_idf_matrix.toarray():\n",
        "#   for j in i:\n",
        "#     if (j != 0):\n",
        "#       print (j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yFr8FMAsbpJ",
        "outputId": "4eaf5d02-657e-456b-dd1d-717db9bcc760"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Names:\n",
            " ['00' '0020115687' '00971562643674' ... 'Û¹Û¸' 'Û¹Û¹' 'ïºØ³Øª']\n",
            "TF-IDF Matrix:\n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. choose one tweets randomly.\n",
        "import random\n",
        "chosen_tweet = random.choice(Tweets)\n",
        "print(\"Chosen Tweet:\", chosen_tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUJVtLSeE_yH",
        "outputId": "5c1fee68-265d-4e94-88e8-5fafd873deaa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen Tweet: @AnonymousUK2022 #Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini #oplran \n",
            "Ø§ÛŒØ±Ø§Ù†Ùˆ Ù¾Ø³ Ù…ÛŒÚ¯ÛŒØ±ÛŒÙ…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SJMju0Tiw9YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2765e128-796b-4b13-c8ba-482d4b9a3e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fb2fe9b1de3f>:16: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cosine_similarity = dot_product / (norm_u * norm_v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Nearest Tweets:\n",
            "========================\n",
            "Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ø±Ù…ÙˆÙ† Ú©Ù‡ Ø³Ø± Ø§ÛŒÙ†ØªØ±Ù†Øª Ùˆ Ø¯ÙˆØ± Ø²Ø¯Ù† ÙÛŒÙ„ØªØ± Ù‡Ø§ Ø­Ø±ÙˆÙ… Ø´Ø¯..\n",
            "#MahsaAmini \n",
            "#Mahsa_Amini \n",
            "#OpIran\n",
            "========================\n",
            "@Chandlershelby1 Ø¨Ø±Ø§ÛŒ\n",
            " #Mahsa_Amini \n",
            "#OpIran \n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "========================\n",
            "Ø§ÙˆÙ†Ø§ÛŒÛŒ Ú©Ù‡ Ø¯ÙˆØ³Øª Ù†Ø¯Ø§Ø±Ù… Ù¾ÛŒØ¬ Ø§ÛŒÙ†Ø³ØªØ§Ø´ÙˆÙ† Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®Ø§Ø±Ø¬ Ø¨Ø´Ù‡ Ø¨Ø¬Ø§ÛŒ Ù†Ø§Ù„Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø²Ù…ÛŒÙ†Ù‡ØŒ ÙÙ‚Ø· Ú©Ø§ÙÛŒÙ‡ Ù¾Ø³Øª Ùˆ Ø§Ø³ØªÙˆØ±ÛŒ Ø­Ù…Ø§ÛŒØª Ø§Ø² Ù…Ø±Ø¯Ù… Ø¨Ø²Ø§Ø±Ù†ØŒ Ù‡Ù…ÛŒÙ†.\n",
            "#MahsaAmini\n",
            "#Mahsa_Amini\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "#OpIran\n",
            "========================\n",
            "Ø§ÛŒÙ†Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒÚ¯Ù† ÙÙ„Ø§Ù† Ø§Ø³ØªØ§Ù† Ùˆ ÙÙ„Ø§Ù† Ø¬Ø§ Ùˆ Ù…Ø±Ú©Ø² Ú©Ø´ÙˆØ± Ø®Ø¨Ø±ÛŒ Ù†ÛŒØ³Øª Ø§ÙˆÙ„ Ø¨Ø±Ù† Ø¨Ø¨ÛŒÙ†Ù† Ú†Ù‚Ø¯Ø± Ø¨Ú†Ù‡Ø§Ù…ÙˆÙ†Ùˆ Ø²Ø¯Ù† Ú©Ø´ØªÙ† Ø¨Ø¹Ø¯ Ø¨ÛŒØ§Ù† Ø§ÛŒÙ†Ùˆ Ø¨Ø®ÙˆØ±Ù†\n",
            "\n",
            "ØªÙØ±Ù‚Ù‡ Ø§ÙÚ©Ù† Ù‡Ø§ÛŒ Ø±Ùˆ Ø§Ø¹ØµØ§Ø¨ Ø³Ø§ÛŒØ¨Ø±ÛŒ\n",
            "\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini\n",
            "========================\n",
            "@mamadporii Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡Ø§ Ø¨ÛŒØ¯Ø§Ø±Ù†\n",
            "Ø§ÛŒÙ†Ùˆ Û²Ûµ Ø±ÙˆØ²Ù‡ Ú©Ù‡ Ø¯Ø§Ø±ÛŒÙ… Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ùˆ Ù„Ù…Ø³ Ù…ÛŒÚ©Ù†ÛŒÙ…\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini \n",
            "#OpIran\n",
            "========================\n",
            "Ù…Ø§ Ù‡Ù…Ù‡ Ù…Ù‡Ø³Ø§ Ù‡Ø³ØªÛŒÙ… Ø¨Ø¬Ù†Ú¯ ØªØ§ Ø¨Ø¬Ù†Ú¯ÛŒÙ…\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "#Mahsa_Amini \n",
            "#MahsaAmini\n",
            "========================\n",
            "@asemanhn @Cherii98 ÛŒÚ©\n",
            "Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "Ø¯Ø®ØªØ± Ø§ÛŒØ±Ø§Ù†ğŸ–¤ğŸ–¤\n",
            "#Mahsa_Amini\n",
            "#OpIran\n",
            "========================\n",
            "@alikarimi_ak8 Ø¨Ø±Ø§ÛŒ Ø§Ù…ÛŒØ¯ Ø¨Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ø§ÛŒ Ø±ÙˆØ´Ù† Ø¨Ø±Ø§ÛŒ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ø²Ù…ÛŒÙ† #Mahsa_Amini\n",
            "========================\n",
            "@OutFarsi @armin_prm #OpIran \n",
            "#Mahsa_Amini \n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "Ù…Ø§ Ù‡Ù…Ù‡ Ø¨Ø§Ù‡Ù… Ù‡Ø³ØªÛŒÙ…\n",
            "========================\n",
            "@Nafise1375 @Godofpersiian Ø®ÛŒÙ„ÛŒØ§ Ø¯Ø§Ø±Ù† Ù‡Ø´ØªÚ¯ Ø§Ø´ØªØ¨Ø§Ù‡ Ù…ÛŒØ²Ù†Ù†ØŒ Ø³Ø§ÛŒØ¨Ø±ÛŒ Ù‡Ù… Ù†ÛŒØ³ØªÙ†Â» Ù„Ø·ÙÙ† Ø¢Ú¯Ø§Ù‡Ø´ÙˆÙ† Ú©Ù†ÛŒÙ†...\n",
            "Ø¯Ù‚Øª Ú©Ù†ÛŒØ¯ #Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ Ø¯Ø±Ø³ØªÙ‡ ÛŒÙ‡ Ø¢Ù†Ø¯Ø±Ù„Ø§ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ù†Ø¯Ø§Ø±Ù‡.#Ø§Ø¹ØªØµØ§Ø¨Ø§Øª_Ø³Ø±Ø§Ø±ÛŒ \n",
            "Ù‡Ø´ØªÚ¯ Ø±Ùˆ Ø®ÙˆØ¯ØªÙˆÙ† Ø¨Ù†ÙˆÛŒØ³ÛŒÙ†ØŒ Ø§Ø² Ø§Ù†ØªØ®Ø§Ø¨Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ØªÙˆÛŒÛŒØªØ± Ø¨Ù‡ØªÙˆÙ† Ù…ÛŒØ¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒÙ†...\n",
            " #MashaAmini \n",
            "#OpIran\n",
            "#Mahsa_Amini\n"
          ]
        }
      ],
      "source": [
        "# 3. find 10 nearest tweets from chosen tweet.\n",
        "\n",
        "# Get the index of the chosen tweet in the tfidf_matrix\n",
        "chosen_tweet_index = np.where(Tweets == chosen_tweet)[0][0]\n",
        "\n",
        "# Get the TF-IDF vector for the chosen tweet\n",
        "chosen_tweet_vector = tf_idf_matrix[chosen_tweet_index]\n",
        "\n",
        "# Calculate the cosine similarity between the chosen tweet and all other tweets\n",
        "similarities = []\n",
        "for i in range(len(Tweets)):\n",
        "    similarity = cosine_similarity(chosen_tweet_vector.toarray()[0], tf_idf_matrix[i].toarray()[0])\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Sort the similarities and get the indices of the 10 nearest tweets\n",
        "nearest_indices = np.argsort(similarities)[::-1][1:11]\n",
        "\n",
        "print(\"10 Nearest Tweets:\")\n",
        "for index in nearest_indices:\n",
        "    print(\"========================\")\n",
        "    print(Tweets[index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_tweet = random.choice(Tweets)\n",
        "print(\"Chosen Tweet:\", chosen_tweet)\n",
        "\n",
        "# Get the index of the chosen tweet in the tfidf_matrix\n",
        "chosen_tweet_index = np.where(Tweets == chosen_tweet)[0][0]\n",
        "\n",
        "# Get the TF-IDF vector for the chosen tweet\n",
        "chosen_tweet_vector = tf_idf_matrix[chosen_tweet_index]\n",
        "\n",
        "# Calculate the cosine similarity between the chosen tweet and all other tweets\n",
        "similarities = []\n",
        "for i in range(len(Tweets)):\n",
        "    similarity = cosine_similarity(chosen_tweet_vector.toarray()[0], tf_idf_matrix[i].toarray()[0])\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Sort the similarities and get the indices of the 10 nearest tweets\n",
        "nearest_indices = np.argsort(similarities)[::-1][1:11]\n",
        "\n",
        "print(\"10 Nearest Tweets:\")\n",
        "for index in nearest_indices:\n",
        "    print(\"========================\")\n",
        "    print(Tweets[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq1wZeHdFjU3",
        "outputId": "0a8d0634-4b53-46ff-82dc-0001d56ebcd1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen Tweet: @Delaramm1127 Ú©ÛŒÙ… ØªÙ‡ÛŒÙˆÙ†Ú¯ \n",
            "#Mahsa_Amini\n",
            "#OpIran\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-fb2fe9b1de3f>:16: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  cosine_similarity = dot_product / (norm_u * norm_v)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Nearest Tweets:\n",
            "========================\n",
            "@Nafise1375 @Godofpersiian Ø®ÛŒÙ„ÛŒØ§ Ø¯Ø§Ø±Ù† Ù‡Ø´ØªÚ¯ Ø§Ø´ØªØ¨Ø§Ù‡ Ù…ÛŒØ²Ù†Ù†ØŒ Ø³Ø§ÛŒØ¨Ø±ÛŒ Ù‡Ù… Ù†ÛŒØ³ØªÙ†Â» Ù„Ø·ÙÙ† Ø¢Ú¯Ø§Ù‡Ø´ÙˆÙ† Ú©Ù†ÛŒÙ†...\n",
            "Ø¯Ù‚Øª Ú©Ù†ÛŒØ¯ #Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ Ø¯Ø±Ø³ØªÙ‡ ÛŒÙ‡ Ø¢Ù†Ø¯Ø±Ù„Ø§ÛŒÙ† Ø¨ÛŒØ´ØªØ± Ù†Ø¯Ø§Ø±Ù‡.#Ø§Ø¹ØªØµØ§Ø¨Ø§Øª_Ø³Ø±Ø§Ø±ÛŒ \n",
            "Ù‡Ø´ØªÚ¯ Ø±Ùˆ Ø®ÙˆØ¯ØªÙˆÙ† Ø¨Ù†ÙˆÛŒØ³ÛŒÙ†ØŒ Ø§Ø² Ø§Ù†ØªØ®Ø§Ø¨Ù‡Ø§ÛŒÛŒ Ú©Ù‡ ØªÙˆÛŒÛŒØªØ± Ø¨Ù‡ØªÙˆÙ† Ù…ÛŒØ¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ú©Ù†ÛŒÙ†...\n",
            " #MashaAmini \n",
            "#OpIran\n",
            "#Mahsa_Amini\n",
            "========================\n",
            "Ø¨Ù‡ Ø®Ø§Ø·Ø± Ù‡Ù…Ù‡ Ø´Ù‡ÛŒØ¯Ø§ÛŒÛŒ Ú©Ù‡ Ø§ÛŒÙ† Ú†Ù†Ø¯ Ø±ÙˆØ² Ùˆ ØªÙ…Ø§Ù… Ø§ÛŒÙ† Ø³Ø§Ù„Ù‡Ø§ Ø¯Ø§Ø¯ÛŒÙ…...\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini \n",
            "#OpIran\n",
            "========================\n",
            "@Chandlershelby1 Ø¨Ø±Ø§ÛŒ\n",
            " #Mahsa_Amini \n",
            "#OpIran \n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "========================\n",
            "Ø§ÙˆÙ†Ø§ÛŒÛŒ Ú©Ù‡ Ø¯ÙˆØ³Øª Ù†Ø¯Ø§Ø±Ù… Ù¾ÛŒØ¬ Ø§ÛŒÙ†Ø³ØªØ§Ø´ÙˆÙ† Ø§Ø² Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø®Ø§Ø±Ø¬ Ø¨Ø´Ù‡ Ø¨Ø¬Ø§ÛŒ Ù†Ø§Ù„Ù‡ Ø¯Ø± Ø§ÛŒÙ† Ø²Ù…ÛŒÙ†Ù‡ØŒ ÙÙ‚Ø· Ú©Ø§ÙÛŒÙ‡ Ù¾Ø³Øª Ùˆ Ø§Ø³ØªÙˆØ±ÛŒ Ø­Ù…Ø§ÛŒØª Ø§Ø² Ù…Ø±Ø¯Ù… Ø¨Ø²Ø§Ø±Ù†ØŒ Ù‡Ù…ÛŒÙ†.\n",
            "#MahsaAmini\n",
            "#Mahsa_Amini\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "#OpIran\n",
            "========================\n",
            "Ø§ÛŒÙ†Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒÚ¯Ù† ÙÙ„Ø§Ù† Ø§Ø³ØªØ§Ù† Ùˆ ÙÙ„Ø§Ù† Ø¬Ø§ Ùˆ Ù…Ø±Ú©Ø² Ú©Ø´ÙˆØ± Ø®Ø¨Ø±ÛŒ Ù†ÛŒØ³Øª Ø§ÙˆÙ„ Ø¨Ø±Ù† Ø¨Ø¨ÛŒÙ†Ù† Ú†Ù‚Ø¯Ø± Ø¨Ú†Ù‡Ø§Ù…ÙˆÙ†Ùˆ Ø²Ø¯Ù† Ú©Ø´ØªÙ† Ø¨Ø¹Ø¯ Ø¨ÛŒØ§Ù† Ø§ÛŒÙ†Ùˆ Ø¨Ø®ÙˆØ±Ù†\n",
            "\n",
            "ØªÙØ±Ù‚Ù‡ Ø§ÙÚ©Ù† Ù‡Ø§ÛŒ Ø±Ùˆ Ø§Ø¹ØµØ§Ø¨ Ø³Ø§ÛŒØ¨Ø±ÛŒ\n",
            "\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini\n",
            "========================\n",
            "@mamadporii Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡Ø§ Ø¨ÛŒØ¯Ø§Ø±Ù†\n",
            "Ø§ÛŒÙ†Ùˆ Û²Ûµ Ø±ÙˆØ²Ù‡ Ú©Ù‡ Ø¯Ø§Ø±ÛŒÙ… Ù…ÛŒØ¨ÛŒÙ†ÛŒÙ… Ùˆ Ù„Ù…Ø³ Ù…ÛŒÚ©Ù†ÛŒÙ…\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "#Mahsa_Amini \n",
            "#OpIran\n",
            "========================\n",
            "Ù…Ø§ Ù‡Ù…Ù‡ Ù…Ù‡Ø³Ø§ Ù‡Ø³ØªÛŒÙ… Ø¨Ø¬Ù†Ú¯ ØªØ§ Ø¨Ø¬Ù†Ú¯ÛŒÙ…\n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ\n",
            "#Mahsa_Amini \n",
            "#MahsaAmini\n",
            "========================\n",
            "@asemanhn @Cherii98 ÛŒÚ©\n",
            "Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "Ø¯Ø®ØªØ± Ø§ÛŒØ±Ø§Ù†ğŸ–¤ğŸ–¤\n",
            "#Mahsa_Amini\n",
            "#OpIran\n",
            "========================\n",
            "@OutFarsi @armin_prm #OpIran \n",
            "#Mahsa_Amini \n",
            "#Ù…Ù‡Ø³Ø§_Ø§Ù…ÛŒÙ†ÛŒ \n",
            "Ù…Ø§ Ù‡Ù…Ù‡ Ø¨Ø§Ù‡Ù… Ù‡Ø³ØªÛŒÙ…\n",
            "========================\n",
            "@alikarimi_ak8 Ø¨Ø±Ø§ÛŒ Ø§Ù…ÛŒØ¯ Ø¨Ù‡ Ø¢ÛŒÙ†Ø¯Ù‡ Ø§ÛŒ Ø±ÙˆØ´Ù† Ø¨Ø±Ø§ÛŒ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø§ÛŒØ±Ø§Ù† Ø²Ù…ÛŒÙ† #Mahsa_Amini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqNCL4kFmvm3"
      },
      "source": [
        "##### Describe advantages and disadvantages of TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GHvpTAZu7ZU"
      },
      "source": [
        "**Advantages:**\n",
        "1. **Term Importance:** TF-IDF highlights important terms in a document by assigning higher weights to words that are more frequent in the document and less frequent in the entire corpus. This allows for effective keyword extraction and helps in identifying the most relevant terms within a document.\n",
        "\n",
        "2. **Document Similarity:** TF-IDF enables the calculation of cosine similarity between documents based on their TF-IDF vector representations. This similarity measure is useful for tasks such as document clustering, information retrieval, and recommendation systems.\n",
        "\n",
        "3. **Language Independence:** TF-IDF is language-independent, meaning it can be applied to documents in any language. It doesn't rely on language-specific rules or heuristics, making it a versatile technique for text analysis across different languages.\n",
        "\n",
        "4. **Computational Efficiency:** TF-IDF can be computed efficiently, especially when using sparse matrix representations. This makes it scalable for large corpora and enables fast retrieval of relevant documents based on query terms.\n",
        "\n",
        "**Disadvantages:**\n",
        "1. **Term Frequency Bias:** TF-IDF heavily relies on term frequency. Overly frequent terms within a document may dominate the TF-IDF score, potentially overshadowing other important terms. This can be mitigated by using term frequency normalization techniques.\n",
        "2. **Lack of Semantic Understanding:** TF-IDF does not capture the semantic meaning of words or the relationships between them. It treats each term independently, which may limit its ability to capture the context or nuanced meaning of phrases or multi-word expressions.\n",
        "3. **Handling Out-of-Vocabulary Words:** TF-IDF is based on a fixed vocabulary derived from the corpus. Out-of-vocabulary words, i.e., words not present in the vocabulary, are typically ignored or treated as noise. This can be a limitation when dealing with specialized or domain-specific terms.\n",
        "4. **Document Length Bias:** Longer documents tend to have higher term frequencies, which can bias the TF-IDF scores. Longer documents may have higher TF-IDF values simply due to more occurrences of terms, even if the terms are not necessarily more important.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INM6vtm2zqJs"
      },
      "source": [
        "# 4. Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TCnxqaVY2zCc"
      },
      "outputs": [],
      "source": [
        "# 1. train a word2vec model base on all tweets\n",
        "# Create a list of tokenized tweets\n",
        "tokenized_tweets = [tweet.split() for tweet in PureText_data]\n",
        "\n",
        "# Train the Word2Vec model\n",
        "model = Word2Vec(sentences=tokenized_tweets, vector_size=100, window=5, min_count=5, workers=4)\n",
        "\n",
        "# Save the trained model for future use\n",
        "model.save(\"tweet_word2vec.model\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. find 10 nearest words from \"Ø¢Ø²Ø§Ø¯ÛŒ\"\n",
        "\n",
        "# Load the trained Word2Vec model\n",
        "model = Word2Vec.load(\"tweet_word2vec.model\")\n",
        "\n",
        "# Find the 10 nearest words to \"Ø¢Ø²Ø§Ø¯ÛŒ\"\n",
        "nearest_words = model.wv.most_similar(\"Ø¢Ø²Ø§Ø¯ÛŒ\", topn=10)\n",
        "\n",
        "# Print the nearest words\n",
        "print(\"10 Nearest Words to 'Ø¢Ø²Ø§Ø¯ÛŒ':\")\n",
        "for word, similarity in nearest_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQyDwe0zI7dM",
        "outputId": "952d6d2f-6d9e-4911-c103-1c6e28acfd7b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Nearest Words to 'Ø¢Ø²Ø§Ø¯ÛŒ':\n",
            "Ø²Ù†Ø¯Ú¯ÛŒØŒ\n",
            "Ø§Ø²Ø§Ø¯ÛŒ\n",
            "Ø²Ù†ØŒ\n",
            "Ø²Ù†\n",
            "Ø§Ø¨Ø§Ø¯ÛŒ\n",
            "Ø²Ù†Ø¯Ú¯ÛŒ\n",
            "Ø§ÛŒØ±Ø§Ù†\n",
            "Ø¢Ø²Ø§Ø¯ÛŒØŒ\n",
            "Ø§Ù…ÛŒØ¯\n",
            "ØŒØ²Ù†Ø¯Ú¯ÛŒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained Word2Vec model\n",
        "model = Word2Vec.load(\"tweet_word2vec.model\")\n",
        "\n",
        "# Find the 10 nearest words to \"Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±\"\n",
        "nearest_words = model.wv.most_similar(\"Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±\", topn=10)\n",
        "\n",
        "# Print the nearest words\n",
        "print(\"10 Nearest Words to 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±':\")\n",
        "for word, similarity in nearest_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nVGvag7JrhB",
        "outputId": "55dada22-cd02-4431-87b8-0771ae4498ce"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 Nearest Words to 'Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±':\n",
            "ÙˆÙ‚ØªÛŒ\n",
            "Ø­Ø±Ù\n",
            "Ø§ÛŒÙ†Ù‡\n",
            "Ø§ÙˆÙ…Ø¯\n",
            "Ú¯ÙˆØ´ÛŒ\n",
            "ÙˆØ§Ø³Ù‡\n",
            "Ø¬Ù…Ø¹\n",
            "Ù‡Ù…ÛŒÙ†\n",
            "Ù‡Ø§Ø´ÙˆÙ†\n",
            "Ø¯ÛŒØ±ÙˆØ²\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37oMUvZcmvm4"
      },
      "source": [
        "##### Describe advantages and disadvantages of Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv39LXf0wkjd"
      },
      "source": [
        "**Advantages:**\n",
        "1. **Capturing Semantic Relationships:** Word2Vec can capture semantic relationships between words by representing them as dense vectors in a continuous vector space. Similar words tend to have similar vector representations, enabling the model to capture word similarity and analogies.\n",
        "\n",
        "2. **Dimensionality Reduction:** Word2Vec reduces the dimensionality of word representations. Instead of representing words as one-hot vectors in a high-dimensional space, Word2Vec provides compact and dense vector representations that capture meaningful semantic information.\n",
        "\n",
        "3. **Contextual Information:** Word2Vec considers the context in which a word appears, allowing it to capture the meaning of words based on their surrounding words. This enables the model to capture syntactic and semantic relationships.\n",
        "\n",
        "4. **Efficiency:** Word2Vec uses an efficient implementation, such as the skip-gram or continuous bag-of-words (CBOW) models, which make it computationally efficient to train on large-scale datasets. Once trained, the model can quickly provide word embeddings for downstream tasks.\n",
        "\n",
        "**Disadvantages:**\n",
        "\n",
        "1. **Lack of Subword Information:** Word2Vec treats words as atomic units and does not capture subword information. Rare or out-of-vocabulary words may not have meaningful embeddings, and the model may struggle with morphologically rich languages or words with multiple meanings.\n",
        "2. **Limited Context Window:** Word2Vec uses a fixed context window size to capture word relationships. This limits the model's ability to capture long-range dependencies or relationships between words that are further apart.\n",
        "3. **Domain-Specific Representations:** Word2Vec embeddings are trained on a specific corpus. If the target domain differs significantly from the training corpus, the embeddings may not capture the specific domain's nuances and may require additional fine-tuning or training on domain-specific data.\n",
        "4. **Polysemy and Homonymy:** Word2Vec treats each word as a single entity, ignoring potential multiple meanings or contexts. This can result in ambiguous representations for polysemous words or different senses of homonymous words.\n",
        "5. **Lack of Compositionality:** Word2Vec does not inherently capture compositional meaning, where the meaning of a phrase or sentence is derived from the combination of individual word meanings. It treats each word independently, limiting its ability to capture complex linguistic structures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSdlWMl64aPN"
      },
      "source": [
        "# 5. Contextualized embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "zgVAEQhyOPxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497ca60d-40d4-4436-bfae-abb6157c7411"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (4.66.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[sentencepiece]) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[sentencepiece]) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "GfKEqNml6eEB"
      },
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "model_name = \"HooshvareLab/bert-base-parsbert-uncased\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uc8hBCnn4cV_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237,
          "referenced_widgets": [
            "acd989ff2db849f5bc4f58a74bcc03f9",
            "db6ff91113484b93b064a19c760619f0",
            "e1e05ebfc7954e22833324ef9b49b596",
            "922606584dea44af869acbc4ce1b1fa3",
            "2517795f56a84f00a9faa4729209756b",
            "fb5011675a83436cb2ca247864a5a15e",
            "41be0e2d046e49bfbd79cda9159110b9",
            "43e0959308f548c8aa9009aea5999bd3",
            "215e369ba33a48288da00ab81f67c3c3",
            "aae3f93e3705435a9d23d09a82627d83",
            "a37b4c05633e4ff1a207edf8db41c6b8",
            "a13a06f25eee46c4b9abf5ff952db4cc",
            "3fdc32f7b64349de8590bbb2dcd32b38",
            "5c1eeccc2b2d40769bd61a90de6931a7",
            "8d6c4b65c14e4b59921de20ceded80ec",
            "5e8fb37893a249bd8ba27873c382a18a",
            "326796a4a763457e9bb42d020dee8400",
            "d6de134583a24f178f0dfc950fa16107",
            "ad37040562b745c0969e4af44db390be",
            "ab286bd5d0f045eba26163fb0aead395",
            "a6b145c08a2e4db1bc5745333f09537f",
            "5dd622bc2d6f4ce0bf1919567558519e",
            "31fb0fbb92aa4f7799d7f0aa98454d10",
            "21ba172c4c6742198281039ac54a25b4",
            "906213a346b247bf951d1c5c3c5f0f4e",
            "3d24b1632d124bb49949f075b1eb1017",
            "e9744aaad78f4589bb686936e7b43e3e",
            "0ae506f3a57141b9b02419699007cfeb",
            "e09d29098aea4c52a85c41652c705823",
            "d3f7b9ab0b4b4d3bbf13206e803aa697",
            "74290b921aaa48ab9b1ed3b12cfa6f20",
            "c0b68feb253246cabd68a4793b813736",
            "2bcb7d2124bb4ef8a285deb105fa5803"
          ]
        },
        "outputId": "e78f5c9f-4e77-47fd-ba69-8f048b710b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acd989ff2db849f5bc4f58a74bcc03f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/654M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a13a06f25eee46c4b9abf5ff952db4cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.22M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31fb0fbb92aa4f7799d7f0aa98454d10"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 1. fine-tune the model base on all tweets\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = tokenizer.batch_encode_plus(\n",
        "    PureText_data,\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        "    max_length=512,  # Adjust as needed\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "OCE6s1CdMWZX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your classification model on top of the BERT base\n",
        "class MyClassifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MyClassifier, self).__init__()\n",
        "        self.bert = model  # Use the pre-trained BERT model as the base\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.fc = torch.nn.Linear(768, num_classes)  # Adjust the input size (768) and output size (num_classes) as needed\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.fc(pooled_output)\n",
        "        return logits\n",
        "\n",
        "# Instantiate your classification model\n",
        "num_classes = 2  # Adjust based on the number of classes for your task\n",
        "classifier = MyClassifier(num_classes)\n",
        "\n",
        "# Define your optimization and loss functions\n",
        "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10  # Adjust the number of epochs as needed\n",
        "batch_size = 32  # Adjust the batch size as needed\n",
        "\n",
        "# Fine-tuning loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to train mode\n",
        "    classifier.train()\n",
        "\n",
        "    # Iterate over the mini-batches of your tokenized data\n",
        "    for i in range(0, len(tokenized_data[\"input_ids\"]), batch_size):\n",
        "        batch_input_ids = tokenized_data[\"input_ids\"][i:i + batch_size]\n",
        "        batch_attention_mask = tokenized_data[\"attention_mask\"][i:i + batch_size]\n",
        "        batch_labels = labels[i:i + batch_size]  # Replace `labels` with your actual label data\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = classifier(batch_input_ids, batch_attention_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(logits, batch_labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print the loss for monitoring\n",
        "        if i % print_every == 0:\n",
        "            print(f\"Epoch: {epoch+1}, Batch: {i+1}/{len(tokenized_data['input_ids'])}, Loss: {loss.item()}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "torch.save(classifier.state_dict(), \"fine_tuned_model.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "X17aeIUNMjAp",
        "outputId": "97f9e3f4-5dd2-4860-8421-20ce542cfdee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'labels' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-7d90bee78cdd>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mbatch_input_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mbatch_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenized_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mbatch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Replace `labels` with your actual label data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Zero the gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. find 10 nearest words from \"Ø¢Ø²Ø§Ø¯ÛŒ\""
      ],
      "metadata": {
        "id": "BGAb56yCMFR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertModel, BertTokenizer\n",
        "\n",
        "# Load the pre-trained BERT model and tokenizer\n",
        "model_name = \"HooshvareLab/bert-base-parsbert-uncased\"\n",
        "model = BertModel.from_pretrained(model_name)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Define the input text\n",
        "input_text = \"Ø¢Ø²Ø§Ø¯ÛŒ\"\n",
        "\n",
        "# Tokenize the input text\n",
        "tokenized_text = tokenizer.tokenize(input_text)\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Convert tokens to tensor\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "\n",
        "# Generate the contextualized embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(tokens_tensor)\n",
        "\n",
        "# Get the embeddings for the input tokens\n",
        "input_embedding = outputs[0][0]  # Embedding for the first token, which represents the input word\n",
        "\n",
        "# Calculate cosine similarity between the input word embedding and each tweet\n",
        "similarities = []\n",
        "for tweet in PureText_data:\n",
        "    # Tokenize and convert tweet to tensor\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "    tweet_indexed_tokens = tokenizer.convert_tokens_to_ids(tweet_tokens)\n",
        "    tweet_tensor = torch.tensor([tweet_indexed_tokens])\n",
        "\n",
        "    # Generate the contextualized embeddings for the tweet\n",
        "    with torch.no_grad():\n",
        "        tweet_outputs = model(tweet_tensor)\n",
        "\n",
        "    # Get the embeddings for the tweet tokens\n",
        "    tweet_embeddings = tweet_outputs[0][0]  # Embeddings for the tweet tokens\n",
        "\n",
        "    # Calculate cosine similarity between input word embedding and tweet embeddings\n",
        "    similarity = np.dot(input_embedding.numpy(), tweet_embeddings.numpy().T) / (\n",
        "        np.linalg.norm(input_embedding.numpy()) * np.linalg.norm(tweet_embeddings.numpy(), axis=1)\n",
        "    )\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Sort the tweets based on cosine similarity in descending order\n",
        "sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "# Get the 10 most similar tweets\n",
        "nearest_tweets = [PureText_data[index] for index in sorted_indices[:10]]\n",
        "\n",
        "# Print the nearest tweets\n",
        "for tweet in nearest_tweets:\n",
        "    print(tweet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9d4mcxUsNILs",
        "outputId": "7d542a6e-5167-4b6d-cf2b-e6b7f880d055"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (20000, 1) + inhomogeneous part.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-0b18ca666682>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Sort the tweets based on cosine similarity in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Get the 10 most similar tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \"\"\"\n\u001b[0;32m-> 1133\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (20000, 1) + inhomogeneous part."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBUkqdX0mvm6"
      },
      "source": [
        "##### Describe advantages and disadvantages of Contextualized embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al-4HT8KxTwd"
      },
      "source": [
        "Advantages:\n",
        "\n",
        "\n",
        "Disadvantages:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "acd989ff2db849f5bc4f58a74bcc03f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db6ff91113484b93b064a19c760619f0",
              "IPY_MODEL_e1e05ebfc7954e22833324ef9b49b596",
              "IPY_MODEL_922606584dea44af869acbc4ce1b1fa3"
            ],
            "layout": "IPY_MODEL_2517795f56a84f00a9faa4729209756b"
          }
        },
        "db6ff91113484b93b064a19c760619f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5011675a83436cb2ca247864a5a15e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_41be0e2d046e49bfbd79cda9159110b9",
            "value": "config.json:â€‡100%"
          }
        },
        "e1e05ebfc7954e22833324ef9b49b596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43e0959308f548c8aa9009aea5999bd3",
            "max": 434,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_215e369ba33a48288da00ab81f67c3c3",
            "value": 434
          }
        },
        "922606584dea44af869acbc4ce1b1fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aae3f93e3705435a9d23d09a82627d83",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a37b4c05633e4ff1a207edf8db41c6b8",
            "value": "â€‡434/434â€‡[00:00&lt;00:00,â€‡5.30kB/s]"
          }
        },
        "2517795f56a84f00a9faa4729209756b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5011675a83436cb2ca247864a5a15e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41be0e2d046e49bfbd79cda9159110b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43e0959308f548c8aa9009aea5999bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "215e369ba33a48288da00ab81f67c3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aae3f93e3705435a9d23d09a82627d83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37b4c05633e4ff1a207edf8db41c6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a13a06f25eee46c4b9abf5ff952db4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fdc32f7b64349de8590bbb2dcd32b38",
              "IPY_MODEL_5c1eeccc2b2d40769bd61a90de6931a7",
              "IPY_MODEL_8d6c4b65c14e4b59921de20ceded80ec"
            ],
            "layout": "IPY_MODEL_5e8fb37893a249bd8ba27873c382a18a"
          }
        },
        "3fdc32f7b64349de8590bbb2dcd32b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_326796a4a763457e9bb42d020dee8400",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d6de134583a24f178f0dfc950fa16107",
            "value": "pytorch_model.bin:â€‡100%"
          }
        },
        "5c1eeccc2b2d40769bd61a90de6931a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad37040562b745c0969e4af44db390be",
            "max": 654186735,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab286bd5d0f045eba26163fb0aead395",
            "value": 654186735
          }
        },
        "8d6c4b65c14e4b59921de20ceded80ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6b145c08a2e4db1bc5745333f09537f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5dd622bc2d6f4ce0bf1919567558519e",
            "value": "â€‡654M/654Mâ€‡[00:09&lt;00:00,â€‡79.2MB/s]"
          }
        },
        "5e8fb37893a249bd8ba27873c382a18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326796a4a763457e9bb42d020dee8400": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6de134583a24f178f0dfc950fa16107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad37040562b745c0969e4af44db390be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab286bd5d0f045eba26163fb0aead395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6b145c08a2e4db1bc5745333f09537f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd622bc2d6f4ce0bf1919567558519e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31fb0fbb92aa4f7799d7f0aa98454d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21ba172c4c6742198281039ac54a25b4",
              "IPY_MODEL_906213a346b247bf951d1c5c3c5f0f4e",
              "IPY_MODEL_3d24b1632d124bb49949f075b1eb1017"
            ],
            "layout": "IPY_MODEL_e9744aaad78f4589bb686936e7b43e3e"
          }
        },
        "21ba172c4c6742198281039ac54a25b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae506f3a57141b9b02419699007cfeb",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e09d29098aea4c52a85c41652c705823",
            "value": "vocab.txt:â€‡100%"
          }
        },
        "906213a346b247bf951d1c5c3c5f0f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3f7b9ab0b4b4d3bbf13206e803aa697",
            "max": 1215509,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74290b921aaa48ab9b1ed3b12cfa6f20",
            "value": 1215509
          }
        },
        "3d24b1632d124bb49949f075b1eb1017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0b68feb253246cabd68a4793b813736",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2bcb7d2124bb4ef8a285deb105fa5803",
            "value": "â€‡1.22M/1.22Mâ€‡[00:00&lt;00:00,â€‡2.35MB/s]"
          }
        },
        "e9744aaad78f4589bb686936e7b43e3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae506f3a57141b9b02419699007cfeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09d29098aea4c52a85c41652c705823": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3f7b9ab0b4b4d3bbf13206e803aa697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74290b921aaa48ab9b1ed3b12cfa6f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0b68feb253246cabd68a4793b813736": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bcb7d2124bb4ef8a285deb105fa5803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}