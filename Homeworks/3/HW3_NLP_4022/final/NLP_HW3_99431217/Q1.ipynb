{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-0syxkWi21"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX0LV_hrWPsG"
      },
      "source": [
        "\n",
        "*   In this question we want to use POS-tagged training set to compute for each word the tag that maximizes $p(t|w)$.\n",
        "*   We will implement a simple tokenizer to deal with sentence boundaries.\n",
        "*   We start by assuming that all unknown words are NN and compute error rate on known and unknown words.\n",
        "*   Then write at least five rules to do a better job of tagging unknown words, and show the difference in error rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lueYCsOI0WgG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00927bb4-ce94-4ff4-de48-d60bba668336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9ppIGG8ZWv1c"
      },
      "outputs": [],
      "source": [
        "def generate_dict(_samples):\n",
        "    \"\"\"\n",
        "    Generate a dictionary that captures the count of each (word, tag) combination from a list of samples.\n",
        "\n",
        "    Args:\n",
        "    _samples (list): List of tuples containing (word, tag) pairs.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are lists of dictionaries with 'tag' and 'count' keys.\n",
        "          Each dictionary in the list represents a unique tag associated with the word and its count.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    Example:\n",
        "      _samples = [('apple', 'fruit'), ('banana', 'fruit'), ('apple', 'fruit'), ('apple', 'color'), ('banana', 'color')]\n",
        "      After calling generate_dict(_samples), the expected output would be:\n",
        "      {\n",
        "          'apple': [\n",
        "              {'tag': 'fruit', 'count': 2},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ],\n",
        "          'banana': [\n",
        "              {'tag': 'fruit', 'count': 1},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ]\n",
        "      }\n",
        "      This represents that 'apple' appeared twice with the tag 'fruit' and once with the tag 'color',\n",
        "      while 'banana' appeared once with both 'fruit' and 'color' tags.\n",
        "\n",
        "    '''\n",
        "\n",
        "    dictionary = {}\n",
        "\n",
        "\n",
        "    ## Your code here\n",
        "    # create the dictionary described in the comments\n",
        "    for word, tag in _samples:\n",
        "        if word not in dictionary:\n",
        "            dictionary[word] = []\n",
        "\n",
        "        # Check if the tag already exists for the word\n",
        "        tag_exists = False\n",
        "        for entry in dictionary[word]:\n",
        "            if entry['tag'] == tag:\n",
        "                entry['count'] += 1\n",
        "                tag_exists = True\n",
        "                break\n",
        "\n",
        "        # If the tag doesn't exist, add a new entry with count 1\n",
        "        if not tag_exists:\n",
        "            dictionary[word].append({'tag': tag, 'count': 1})\n",
        "    ## End Code\n",
        "    def get_tag_counts(subitem):\n",
        "        return subitem['count']\n",
        "\n",
        "    for item in dictionary:\n",
        "        sorted(dictionary[item], key=get_tag_counts, reverse=True)\n",
        "\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C-wu5AVoX_rN"
      },
      "outputs": [],
      "source": [
        "def predict_tag(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is assigned.\n",
        "    - Tags are assigned based on the highest count for known words.\n",
        "      - If there are more than 1 tag for a given word, the tag with the highest count is chosen.\n",
        "      - If there is only 1 tag available, it is returned directly.\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = 0\n",
        "    for item in _test_set:\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "        if word in _tag_dict:\n",
        "            # Predict the tag based on the highest count\n",
        "            prediction = _tag_dict[word][0]['tag'] ## Your code here\n",
        "        else:\n",
        "            # Assign 'NN' tag for unknown words\n",
        "            prediction = 'NN' ## Your code here\n",
        "        if prediction == true_tag:\n",
        "          accuracy = accuracy + 1 ## Your code here\n",
        "\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"Assuming that all unknown words are NN\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SgXAgTDrcbYl"
      },
      "outputs": [],
      "source": [
        "def predict_tag_with_improvements(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary, with additional rules for unknown words.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is initially assigned.\n",
        "    - Additional rules are applied to analyze unknown words and assign more specific tags based on patterns observed in the word:\n",
        "        - 'VBG' (verb, gerund) for words ending in 'ing'\n",
        "        - 'NP$' (noun, possessive) for words ending in \"'s\"\n",
        "        - 'NNS' (noun, plural) for words ending in 's'\n",
        "        - 'RB' (adverb) for words ending in 'ly'\n",
        "        - 'VBN' (verb, past participle) for words ending in 'ed'\n",
        "        - 'JJ' (adjective) for words matching certain patterns like 'ble', 'ish', 'ful', etc.\n",
        "        - 'CD' (cardinal numeral) for numeric strings\n",
        "        - 'NP' (noun, proper singular) for capitalized words\n",
        "    \"\"\"\n",
        "\n",
        "    ## Your code here\n",
        "    accuracy = 0\n",
        "    for item in _test_set:\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "\n",
        "        if word in _tag_dict:\n",
        "            # Predict the tag based on the highest count\n",
        "            prediction = _tag_dict[word][0]['tag']\n",
        "        else:\n",
        "            # Assign 'NN' tag for unknown words\n",
        "            prediction = 'NN'\n",
        "\n",
        "            # Apply additional rules for unknown words\n",
        "            if word.endswith('ing'):\n",
        "                prediction = 'VBG'\n",
        "            elif word.endswith(\"'s\"):\n",
        "                prediction = 'NP$'\n",
        "            elif word.endswith('s'):\n",
        "                prediction = 'NNS'\n",
        "            elif word.endswith('ly'):\n",
        "                prediction = 'RB'\n",
        "            elif word.endswith('ed'):\n",
        "                prediction = 'VBN'\n",
        "            elif any(pattern in word for pattern in ['ble', 'ish', 'ful']):\n",
        "                prediction = 'JJ'\n",
        "            elif word.isdigit():\n",
        "                prediction = 'CD'\n",
        "            elif word[0].isupper():\n",
        "                prediction = 'NP'\n",
        "\n",
        "        if prediction == true_tag:\n",
        "            accuracy += 1\n",
        "    ## End Code\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"With additional rules for unknown words\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0P6OX_pEh_tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45841eff-a346-46ff-e0be-0a891eb1a5f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of training set:     75415\n",
            "length of testing set:      25139\n",
            "intersection:               3429\n",
            "Assuming that all unknown words are NN\n",
            ">> accuracy: 0.8184096423883209\n",
            "With additional rules for unknown words\n",
            ">> accuracy: 0.8626039221926091\n",
            "1110 more words got correctly classified.\n"
          ]
        }
      ],
      "source": [
        "CORPUS = brown.tagged_words(categories='news')\n",
        "CORPUS_SIZE = len(brown.tagged_words(categories='news'))\n",
        "\n",
        "CUT_OFF = math.floor(CORPUS_SIZE * 0.75)\n",
        "\n",
        "# section off training and testing lists from corpus\n",
        "training_list = CORPUS[:CUT_OFF]\n",
        "testing_list = CORPUS[CUT_OFF:]\n",
        "\n",
        "# duplicates are ignored in sets\n",
        "training_set = set(training_list)\n",
        "testing_set = set(testing_list)\n",
        "intersection = training_set.intersection(testing_set)\n",
        "\n",
        "print(f\"length of training set:     {len(training_list)}\")\n",
        "print(f\"length of testing set:      {len(testing_list)}\")\n",
        "\n",
        "# uncomment to see how much the training set and testing set overlap\n",
        "print(f\"intersection:               {len(intersection)}\")\n",
        "\n",
        "# uncomment to survey tagged corpus\n",
        "# print(training_set)\n",
        "\n",
        "tag_dict = generate_dict(training_list)\n",
        "accurary_base = predict_tag(testing_list, tag_dict)\n",
        "accurary_impr = predict_tag_with_improvements(testing_list, tag_dict)\n",
        "delta = math.floor((accurary_impr - accurary_base) * len(testing_list))\n",
        "print(f\"{delta} more words got correctly classified.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, a corpus of tagged words from the 'news' category of the Brown corpus is used to train and test a tag prediction model. The corpus is split into a training set and a testing set based on a specified cutoff point.\n",
        "\n",
        "The training set is used to generate a tag dictionary using the `generate_dict` function. This dictionary captures the count of each (word, tag) combination in the training set.\n",
        "\n",
        "The testing set is then used to evaluate the accuracy of the tag prediction model. The `predict_tag` function is called to predict the tags for the words in the testing set based on the tag dictionary generated from the training set. The accuracy of the predictions is calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "The process is repeated with the `predict_tag_with_improvements` function, which applies additional rules for predicting tags for unknown words. The accuracy of the improved predictions is also calculated.\n",
        "\n",
        "The results of the code execution are as follows:\n",
        "- Length of the training set: 75,415 words\n",
        "- Length of the testing set: 25,139 words\n",
        "- Intersection between the training and testing sets: 3,429 words (words that appear in both sets)\n",
        "\n",
        "The accuracy of the tag predictions without the additional rules for unknown words is approximately 0.8184 (81.84%). This means that around 81.84% of the predicted tags match the true tags in the testing set.\n",
        "\n",
        "After applying the additional rules for unknown words, the accuracy of the predictions improves to approximately 0.8626 (86.26%). This means that around 86.26% of the predicted tags match the true tags in the testing set. The improvement in accuracy is significant, with 1,110 more words correctly classified compared to the base model without the additional rules.\n",
        "\n",
        "The analysis suggests that the additional rules for unknown words help to assign more specific tags based on observed patterns in the words. This leads to a higher accuracy in predicting the correct tags for unknown words in the testing set."
      ],
      "metadata": {
        "id": "8bnZkjTpFDNv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0EY8XNVirmv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}